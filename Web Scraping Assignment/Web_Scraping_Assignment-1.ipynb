{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a59d5d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bs4 in c:\\users\\kartik negi\\appdata\\roaming\\python\\python39\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda33\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda33\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda33\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda33\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda33\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda33\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda33\\lib\\site-packages (from requests) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f7cbef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a27d4633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heading Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Heading Text\n",
       "0           Welcome to Wikipedia\n",
       "1  From today's featured article\n",
       "2               Did you know ...\n",
       "3                    In the news\n",
       "4                    On this day\n",
       "5       Today's featured picture\n",
       "6       Other areas of Wikipedia\n",
       "7    Wikipedia's sister projects\n",
       "8            Wikipedia languages"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Q-1 Write a python program to display all the header tags from wikipedia.org and make data frame.\n",
    "wiki=requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup=BeautifulSoup(wiki.content)\n",
    "headings=[]\n",
    "for i in soup.find_all('span', class_=\"mw-headline\"):\n",
    "    headings.append(i.text)\n",
    "headings\n",
    "data = {'Heading Text': headings}\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8b8b6776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of the President</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name of the President\n",
       "0           Shri Ram Nath Kovind\n",
       "1          Shri Pranab Mukherjee\n",
       "2   Smt Pratibha Devisingh Patil\n",
       "3         DR. A.P.J. Abdul Kalam\n",
       "4           Shri K. R. Narayanan\n",
       "5        Dr Shankar Dayal Sharma\n",
       "6            Shri R Venkataraman\n",
       "7               Giani Zail Singh\n",
       "8      Shri Neelam Sanjiva Reddy\n",
       "9       Dr. Fakhruddin Ali Ahmed\n",
       "10  Shri Varahagiri Venkata Giri\n",
       "11              Dr. Zakir Husain\n",
       "12  Dr. Sarvepalli Radhakrishnan\n",
       "13           Dr. Rajendra Prasad"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Q-2 Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
    "###from https://presidentofindia.nic.in/former-presidents.htm and make data frame.\n",
    "president=requests.get('https://presidentofindia.nic.in/former-presidents')\n",
    "soup=BeautifulSoup(president.content)\n",
    "name=[]\n",
    "termofoffice=[]\n",
    "for i in soup.find_all(['h3']):\n",
    "    name.append(i.text)\n",
    "name\n",
    "data={'Name of the President':name}\n",
    "df=pd.DataFrame(data)\n",
    "df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "dd9bcc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>23</td>\n",
       "      <td>2,714</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>20</td>\n",
       "      <td>2316</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>36</td>\n",
       "      <td>4081</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>27</td>\n",
       "      <td>2806</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>England</td>\n",
       "      <td>24</td>\n",
       "      <td>2426</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>19</td>\n",
       "      <td>1910</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>28</td>\n",
       "      <td>2661</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>16</td>\n",
       "      <td>1404</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>32</td>\n",
       "      <td>2794</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>38</td>\n",
       "      <td>2582</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team Matches Points Rating\n",
       "1      Australia      23  2,714    118\n",
       "2       Pakistan      20   2316    116\n",
       "3          India      36   4081    113\n",
       "4    New Zealand      27   2806    104\n",
       "5        England      24   2426    101\n",
       "6   South Africa      19   1910    101\n",
       "7     Bangladesh      28   2661     95\n",
       "8    Afghanistan      16   1404     88\n",
       "9      Sri Lanka      32   2794     87\n",
       "10   West Indies      38   2582     68"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Q-3 Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "odi = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup = BeautifulSoup(odi.content,'html.parser')\n",
    "#a) Top 10 odi team with in mens cricket along with the records for matches,points and rating.\n",
    "name =[]\n",
    "for i in soup.find_all('span', class_='u-hide-phablet')[:10]:\n",
    "    name.append(i.text)\n",
    "\n",
    "australia = soup.find('td',class_=\"rankings-block__banner--matches\")\n",
    "rest_team = []\n",
    "for i in soup.find_all('td',class_ = \"table-body__cell u-center-text\"):\n",
    "    rest_team.append(i.text)\n",
    "    \n",
    "   \n",
    "matches = [int(num.replace(',', '')) for num in rest_team if len(num.replace(',', '')) == 2][:9]\n",
    "matches.insert(0,australia.text)\n",
    "\n",
    "australia_point = soup.find('td', class_=\"rankings-block__banner--points\")\n",
    "\n",
    "points = [int(num.replace(',', '')) for num in rest_team if len(num.replace(',', '')) == 4][:9]\n",
    "points.insert(0,australia_point.text)\n",
    "\n",
    "australia_rating = soup.find('td', class_=\"rankings-block__banner--rating u-text-right\").get_text(strip=True)\n",
    "\n",
    "#Rating of teams\n",
    "rating = []\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\")[:9]:\n",
    "    rating.append(i.text)\n",
    "    \n",
    "rating.insert(0, australia_rating)\n",
    "    \n",
    "df = pd.DataFrame({'Team':name,'Matches':matches,'Points':points,'Rating':rating},index = range(1,11))\n",
    "df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7e76816a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harry Tector</td>\n",
       "      <td>IRE</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Name Team Rating\n",
       "1              Babar Azam  PAK    886\n",
       "2   Rassie van der Dussen   SA    777\n",
       "3            Fakhar Zaman  PAK    755\n",
       "4             Imam-ul-Haq  PAK    745\n",
       "5            Shubman Gill  IND    743\n",
       "6            Harry Tector  IRE    726\n",
       "7            David Warner  AUS    726\n",
       "8         Quinton de Kock   SA    718\n",
       "9             Virat Kohli  IND    705\n",
       "10            Steve Smith  AUS    702"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "player = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "soup = BeautifulSoup(player.content,'html.parser')\n",
    "soup\n",
    "b = soup.find('div',class_=\"rankings-block__banner--name\")\n",
    "\n",
    "players = []\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\")[:9]:\n",
    "    x = i.get_text(strip=True)\n",
    "    players.append(x)\n",
    "players.insert(0,b.text)\n",
    "\n",
    "t = soup.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "m = t.get_text(strip = True)\n",
    "d= m.replace('886','')\n",
    "\n",
    "team = []\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\")[:9]:\n",
    "    team.append(i.text)\n",
    "team.insert(0,d)\n",
    "\n",
    "r = soup.find('div',class_=\"rankings-block__banner--rating\")\n",
    "\n",
    "#their individual rating\n",
    "rating = []\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\")[:9]:\n",
    "    rating.append(i.text)\n",
    "rating.insert(0,r.text)\n",
    "\n",
    "df = pd.DataFrame({'Player Name':players,'Team':team,'Rating':rating},index = range(1,11))\n",
    "df\n",
    "\n",
    "## i was not able to do part-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3908be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q-4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cd4155d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>26</td>\n",
       "      <td>4,290</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>31</td>\n",
       "      <td>3875</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>3098</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India</td>\n",
       "      <td>30</td>\n",
       "      <td>3039</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>28</td>\n",
       "      <td>2688</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>29</td>\n",
       "      <td>2743</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>17</td>\n",
       "      <td>1284</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>12</td>\n",
       "      <td>820</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>13</td>\n",
       "      <td>883</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>1678</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team Matches Points Rating\n",
       "1      Australia      26  4,290    165\n",
       "2        England      31   3875    165\n",
       "3   South Africa      26   3098    165\n",
       "4          India      30   3039    165\n",
       "5    New Zealand      28   2688    165\n",
       "6    West Indies      29   2743    165\n",
       "7     Bangladesh      17   1284    165\n",
       "8      Sri Lanka      12    820    165\n",
       "9       Thailand      13    883    165\n",
       "10      Pakistan      27   1678    165"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "odiwomen = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup = BeautifulSoup(odiwomen.content,'html.parser')\n",
    "soup\n",
    "\n",
    "name =[]\n",
    "for i in soup.find_all('span', class_='u-hide-phablet')[:10]:\n",
    "    name.append(i.text)\n",
    "\n",
    "    \n",
    "matches1 = soup.find('td',class_=\"rankings-block__banner--matches\")\n",
    "list1 = []\n",
    "for i in soup.find_all('td',class_ = \"table-body__cell u-center-text\"):\n",
    "    list1.append(i.text)\n",
    "    \n",
    "LC = [int(num.replace(',', '')) for num in list1 if len(num.replace(',', '')) == 2]\n",
    "LC.insert(0,matches1.text)\n",
    "Matches = LC[0:10]\n",
    "\n",
    "\n",
    "Points = soup.find('td', class_=\"rankings-block__banner--points\")\n",
    "\n",
    "LC1 = [int(num.replace(',', '')) for num in list1 if len(num.replace(',', '')) >= 3]\n",
    "LC1.insert(0,Points.text)\n",
    "points = LC1[0:10]\n",
    "\n",
    "Ratings_1 = soup.find('td', class_=\"rankings-block__banner--rating u-text-right\").get_text(strip=True)\n",
    "\n",
    "Rating = []\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\")[:9]:\n",
    "    rating.append(i.text)\n",
    "    \n",
    "Rating.insert(0, Ratings_1)\n",
    "\n",
    "df = pd.DataFrame({'Team':name,'Matches':Matches,'Points':points,'Rating':Rating},index = range(1,11))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "94c5b31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natalie Sciver-Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player_Name Team Rating\n",
       "1   Natalie Sciver-Brunt  ENG    803\n",
       "2    Chamari Athapaththu   SL    758\n",
       "3            Beth Mooney  AUS    751\n",
       "4        Laura Wolvaardt   SA    732\n",
       "5        Smriti Mandhana  IND    708\n",
       "6           Alyssa Healy  AUS    702\n",
       "7       Harmanpreet Kaur  IND    694\n",
       "8           Ellyse Perry  AUS    686\n",
       "9            Meg Lanning  AUS    682\n",
       "10       Stafanie Taylor   WI    618"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b) Top 10 women’s ODI Batting players along with the records of their team and rating\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "soup = BeautifulSoup(page.content,'html.parser')\n",
    "soup\n",
    "\n",
    "b = soup.find('div',class_=\"rankings-block__banner--name\")\n",
    "\n",
    "players = []\n",
    "for i in soup.find_all('td',class_=\"table-body__cell name\")[:9]:\n",
    "    x = i.get_text(strip=True)\n",
    "    players.append(x)\n",
    "players.insert(0,b.text)\n",
    "\n",
    "\n",
    "tt = soup.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "ff = tt.get_text(strip = True)\n",
    "d= ff.replace('803','')\n",
    "\n",
    "team = []\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\")[:9]:\n",
    "    team.append(i.text)\n",
    "team.insert(0,d)\n",
    "\n",
    "ratings = soup.find('div',class_=\"rankings-block__banner--rating\")\n",
    "\n",
    "rating = []\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\")[:9]:\n",
    "    rating.append(i.text)\n",
    "rating.insert(0,ratings.text)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Player_Name':players,'Team':team,'Rating':rating},index = range(1,11))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "##I was not able to attempt the 3rd part of the question.(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab12659",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q-5) i was not able to solve this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f3075d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q-6) Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
    "##days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles)\n",
    "ai = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "soup = BeautifulSoup(ai.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e23d477c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>David Silver, Satinder Singh, Doina Precup, Ri...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Margaret A. Boden</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Guni Sharon, Roni Stern, Ariel Felner, Nathan ...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Knowledge graphs as tools for explainable mach...</td>\n",
       "      <td>Ilaria Tiddi, Stefan Schlobach</td>\n",
       "      <td>January 2022</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Henry Prakken, Giovanni Sartor</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Richard S. Sutton, Doina Precup, Satinder Singh</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Kjersti Aas, Martin Jullum, Anders Løland</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Wenhan Luo, Junliang Xing and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Saurabh Arora, Prashant Doshi</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>Jasper van der Waa, Elisabeth Nieuwburg, Anita...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Explainable AI tools for legal reasoning about...</td>\n",
       "      <td>Joe Collenette, Katie Atkinson, Trevor Bench-C...</td>\n",
       "      <td>April 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hard choices in artificial intelligence</td>\n",
       "      <td>Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz</td>\n",
       "      <td>November 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Assessing the communication gap between AI mod...</td>\n",
       "      <td>Oskar Wysocki, Jessica Katharine Davies and 5 ...</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Nolan Bard, Jakob N. Foerster and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Ron Kohavi, George H. John</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Séverin Lemaignan, Mathieu Warnier and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The multifaceted impact of Ada Lovelace in the...</td>\n",
       "      <td>Luigia Carlucci Aiello</td>\n",
       "      <td>June 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Robot ethics: Mapping the issues for a mechani...</td>\n",
       "      <td>Patrick Lin, Keith Abney, George Bekey</td>\n",
       "      <td>April 2011</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Reward (Mis)design for autonomous driving</td>\n",
       "      <td>W. Bradley Knox, Alessandro Allievi and 3 more</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Planning and acting in partially observable st...</td>\n",
       "      <td>Leslie Pack Kaelbling, Michael L. Littman, Ant...</td>\n",
       "      <td>May 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What do we want from Explainable Artificial In...</td>\n",
       "      <td>Markus Langer, Daniel Oster and 6 more</td>\n",
       "      <td>July 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "1                                    Reward is enough   \n",
       "2   Explanation in artificial intelligence: Insigh...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Conflict-based search for optimal multi-agent ...   \n",
       "5   Knowledge graphs as tools for explainable mach...   \n",
       "6   Law and logic: A review from an argumentation ...   \n",
       "7   Between MDPs and semi-MDPs: A framework for te...   \n",
       "8   Explaining individual predictions when feature...   \n",
       "9       Multiple object tracking: A literature review   \n",
       "10  A survey of inverse reinforcement learning: Ch...   \n",
       "11  Evaluating XAI: A comparison of rule-based and...   \n",
       "12  Explainable AI tools for legal reasoning about...   \n",
       "13            Hard choices in artificial intelligence   \n",
       "14  Assessing the communication gap between AI mod...   \n",
       "15  Explaining black-box classifiers using post-ho...   \n",
       "16  The Hanabi challenge: A new frontier for AI re...   \n",
       "17              Wrappers for feature subset selection   \n",
       "18  Artificial cognition for social human–robot in...   \n",
       "19  A review of possible effects of cognitive bias...   \n",
       "20  The multifaceted impact of Ada Lovelace in the...   \n",
       "21  Robot ethics: Mapping the issues for a mechani...   \n",
       "22          Reward (Mis)design for autonomous driving   \n",
       "23  Planning and acting in partially observable st...   \n",
       "24  What do we want from Explainable Artificial In...   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "1   David Silver, Satinder Singh, Doina Precup, Ri...    October 2021   \n",
       "2                                         Tim Miller    February 2019   \n",
       "3                                  Margaret A. Boden      August 1998   \n",
       "4   Guni Sharon, Roni Stern, Ariel Felner, Nathan ...   February 2015   \n",
       "5                     Ilaria Tiddi, Stefan Schlobach     January 2022   \n",
       "6                     Henry Prakken, Giovanni Sartor     October 2015   \n",
       "7    Richard S. Sutton, Doina Precup, Satinder Singh      August 1999   \n",
       "8          Kjersti Aas, Martin Jullum, Anders Løland   September 2021   \n",
       "9                Wenhan Luo, Junliang Xing and 4 more      April 2021   \n",
       "10                     Saurabh Arora, Prashant Doshi      August 2021   \n",
       "11  Jasper van der Waa, Elisabeth Nieuwburg, Anita...   February 2021   \n",
       "12  Joe Collenette, Katie Atkinson, Trevor Bench-C...      April 2023   \n",
       "13  Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz    November 2021   \n",
       "14  Oskar Wysocki, Jessica Katharine Davies and 5 ...      March 2023   \n",
       "15  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...        May 2021   \n",
       "16          Nolan Bard, Jakob N. Foerster and 13 more      March 2020   \n",
       "17                        Ron Kohavi, George H. John    December 1997   \n",
       "18      Séverin Lemaignan, Mathieu Warnier and 3 more       June 2017   \n",
       "19   Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz        June 2021   \n",
       "20                            Luigia Carlucci Aiello        June 2016   \n",
       "21            Patrick Lin, Keith Abney, George Bekey       April 2011   \n",
       "22     W. Bradley Knox, Alessandro Allievi and 3 more      March 2023   \n",
       "23  Leslie Pack Kaelbling, Michael L. Littman, Ant...        May 1998   \n",
       "24             Markus Langer, Daniel Oster and 6 more       July 2021   \n",
       "\n",
       "                                            Paper URL  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_titles = []\n",
    "for i in soup.find_all('h2',class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"):\n",
    "    paper_titles.append(i.text)\n",
    "     \n",
    "Authors = []\n",
    "for i in soup.find_all('span',class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    Authors.append(i.text)\n",
    "\n",
    "    \n",
    "Published_Date = []\n",
    "for i in soup.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    Published_Date.append(i.text)\n",
    "    \n",
    " \n",
    "paper_url=[]\n",
    "for i in soup.find_all('a',class_=\"sc-5smygv-0 fIXTHm\"):\n",
    "    x = i['href']\n",
    "    paper_url.append(x)   \n",
    "    \n",
    "df = pd.DataFrame({'Paper Title':paper_titles,'Authors':Authors,'Published Date':Published_Date,'Paper URL':paper_url},index = range(1,25))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fbb1a721",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Q-7) Write a python program to scrape mentioned details from dineout.co.in and make data frame.\n",
    "restaurants = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "soup = BeautifulSoup(page.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cff9aa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lists = []\n",
    "for i in soup.find_all('div',class_=\"restnt-card restaurant\"):\n",
    "    Lists.append(i.text)\n",
    "\n",
    "  \n",
    "name = []\n",
    "for restaurant in soup.find_all('div', class_='restnt-card restaurant'):\n",
    "    text = restaurant.get_text()\n",
    "    votes = text.split('votes')[1].split(',')[0]\n",
    "    name.append(votes)\n",
    "        \n",
    "cuisine = []\n",
    "for i in soup.find_all('div', class_='restnt-card restaurant'):\n",
    "    text = i.get_text()\n",
    "    x = text.split('|')[1]\n",
    "    cuisine.append(x)\n",
    "    \n",
    "   \n",
    "location = []\n",
    "for i in soup.find_all('div', class_ = 'restnt-loc ellipsis'):\n",
    "    location.append(i.text)\n",
    "    \n",
    "\n",
    "ratings = []\n",
    "for i in soup.find_all('div', class_=\"restnt-rating rating-4\"):\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "    \n",
    "images = []\n",
    "for i in soup.find_all('img', class_ ='no-img'):\n",
    "    images.append(i['data-src'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "def29220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Castle BarbequeConnaught Place</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle's BarbequePacific Mall</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India GrillHilton Garden Inn</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Barbeque TimesM2K Corporate Park</td>\n",
       "      <td>North Indian, Continental, Chinese, South Indian</td>\n",
       "      <td>M2K Corporate Park,Sector 51, Gurgaon</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Restaurant Name  \\\n",
       "1                     Castle BarbequeConnaught Place   \n",
       "2      Cafe KnoshThe Leela Ambience Convention Hotel   \n",
       "3                      Castle's BarbequePacific Mall   \n",
       "4                       India GrillHilton Garden Inn   \n",
       "5               The Barbeque CompanyGardens Galleria   \n",
       "6               Delhi BarbequeTaurus Sarovar Portico   \n",
       "7  The Monarch - Bar Be Que VillageIndirapuram Ha...   \n",
       "8               The Barbeque TimesM2K Corporate Park   \n",
       "9            Indian Grill RoomSuncity Business Tower   \n",
       "\n",
       "                                             Cuisine  \\\n",
       "1                              Chinese, North Indian   \n",
       "2                               Italian, Continental   \n",
       "3                              Chinese, North Indian   \n",
       "4                              North Indian, Italian   \n",
       "5                              North Indian, Chinese   \n",
       "6                                       North Indian   \n",
       "7                                       North Indian   \n",
       "8   North Indian, Continental, Chinese, South Indian   \n",
       "9                              North Indian, Mughlai   \n",
       "\n",
       "                                            Location Ratings  \\\n",
       "1                     Connaught Place, Central Delhi       4   \n",
       "2  The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "3             Pacific Mall,Tagore Garden, West Delhi     3.9   \n",
       "4               Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "5                 Gardens Galleria,Sector 38A, Noida     3.9   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi     3.7   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.8   \n",
       "8              M2K Corporate Park,Sector 51, Gurgaon     4.1   \n",
       "9   Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "\n",
       "                                           Image URL  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Restaurant Name': name, 'Cuisine': cuisine, 'Location':location, 'Ratings':ratings, 'Image URL':images},index = range(1,10))\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
